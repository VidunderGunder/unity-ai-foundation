default_settings:
  trainer_type: ppo
  max_steps: 500000
  keep_checkpoints: 5
  checkpoint_interval: 500000
  threaded: true
  hyperparameters:
    learning_rate_schedule: linear
    beta: 0.005
    epsilon: 0.2
    lambd: 0.95
    num_epoch: 3
    buffer_init_steps: 0
    init_entcoef: 1
    save_replay_buffer: false
    tau: 0.005
    steps_per_update: 1
    reward_signal_num_update: steps_per_update
    test: rrrr
    dfg: dfgsdf
  network_settings:
    hidden_units: 128
    num_layers: 2
    normalize: false
    vis_encode_type: simple
    memory:
      memory_size: 128
      sequence_length: 64
  reward_signals:
    strength: 1
    num_layers: 0.99
    learning_rate: 0.0003
    gail:
      strength: 1
      gamma: 0.99
      demo_path: C:/Users/amkle/Documents/Unity/arduino-unity/Build/arduino.exe
      learning_rate: 0.0003
      use_actions: false
      use_vail: false
      network_settings:
        hidden_units: 128
        num_layers: 2
        normalize: false
        vis_encode_type: simple
checkpoint_settings:
  run_id: mlady
  load_model: false
  resume: false
  force: false
  train_model: false
  inference: false
  results_dir: Results
engine_settings:
  quality_level: 5
  target_frame_rate: -1
  capture_frame_rate: 60
  no_graphics: false
  width: 84
  height: 84
torch_settings:
  device: cuda
debug: false
